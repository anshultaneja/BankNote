{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bank Note.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshultaneja/BankNote/blob/main/Bank_Note.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXXXtedzVzV"
      },
      "source": [
        "### **Introduction**\n",
        "\n",
        "Classification is a process of dividing the given data points into two or more classes. When the number of classes = 2, it is known as Binary Classification.\n",
        "\n",
        "In this notebook, we'll be performing Binary Classification to predict if a note is genuine or not.\n",
        "\n",
        "There are 2 classes:\n",
        "\n",
        "1. Note is genuine (class=1)\n",
        "2. Note is not genuine (class=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1UsmC95zHOH"
      },
      "source": [
        "### **Data Description**\n",
        "\n",
        "VWTI: Variance of Wavelet Transformed Image\n",
        "\n",
        "SWTI: Skewness of Wavelet Transformed Image\n",
        "\n",
        "CWTI: Curtosis of Wavelet Transformed Image\n",
        "\n",
        "EI: Entropy of Image\n",
        "\n",
        "Class: Class (1: genuine, 0: forged)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY6ovKb_zuEI"
      },
      "source": [
        "# Loading the basic Data Science Libraries\n",
        "In data science, numpy, pandas and matplotlib are most commonly used libraries. We chose alias names for our libraries for the sake of our convenience (numpy --> np and pandas --> pd, matplotlib.pyplot as plt)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJAEk7nbyE0P"
      },
      "source": [
        "import numpy as np  # for matrix operations\n",
        "import pandas as pd  # for loading CSV Files\n",
        "import matplotlib.pyplot as plt # for Data Visualizationw"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcpvRAk7z_Sb"
      },
      "source": [
        "# Loading Data\n",
        "Pandas module is used for reading files. Since we have our data in '.csv' format, we will use 'read_csv()' function for loading the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44mclUsIygQV"
      },
      "source": [
        "bank_note_data = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/bank_note_data/training_set_label.csv\" )"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MazbNClU0YG2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b35fa8bd-dceb-468c-a097-24fcb7880ca8"
      },
      "source": [
        "bank_note_data.head() #head function displays the first 5 rows by default"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VWTI</th>\n",
              "      <th>SWTI</th>\n",
              "      <th>CWTI</th>\n",
              "      <th>EI</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.2634</td>\n",
              "      <td>-4.4862</td>\n",
              "      <td>3.6558</td>\n",
              "      <td>-0.612510</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.2718</td>\n",
              "      <td>1.7837</td>\n",
              "      <td>2.1161</td>\n",
              "      <td>0.613340</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-3.9411</td>\n",
              "      <td>-12.8792</td>\n",
              "      <td>13.0597</td>\n",
              "      <td>-3.312500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.5195</td>\n",
              "      <td>-3.2633</td>\n",
              "      <td>3.0895</td>\n",
              "      <td>-0.984900</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.5698</td>\n",
              "      <td>-4.4076</td>\n",
              "      <td>5.9856</td>\n",
              "      <td>0.078002</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     VWTI     SWTI     CWTI        EI  Class\n",
              "0  2.2634  -4.4862   3.6558 -0.612510      0\n",
              "1  3.2718   1.7837   2.1161  0.613340      0\n",
              "2 -3.9411 -12.8792  13.0597 -3.312500      1\n",
              "3  0.5195  -3.2633   3.0895 -0.984900      0\n",
              "4  2.5698  -4.4076   5.9856  0.078002      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr3LGXdL0o1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c8b7c7-9c2b-4316-e739-73eec4dcfb5c"
      },
      "source": [
        "bank_note_data.shape # This gives the shape of the DataFrame i.e the (no. of rows, no. of columns)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1096, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp_-PgGV0_uF"
      },
      "source": [
        "# Separating Input and Target Variable\n",
        "**Target Variable/ Independent Variable(y):** Our objective is to detect the presence of heart disease. Thus, our target variable will be the column that indicates whether heart disease is present or not. \n",
        "\n",
        "We'll store that column in a variable y.\n",
        "\n",
        "**Input Variables/ Dependent Variables(X):** The remaining columns, without the Target variable will be stored in variable X."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrrgFsb41EqW"
      },
      "source": [
        "X = bank_note_data.drop('Class', axis=1) #Input variables\n",
        "# axis=1 indicates that a column will be dropped\n",
        "y = bank_note_data['Class']  # Target variable"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXfohC6u1eu-"
      },
      "source": [
        "# Splitting into Train and Test Sets\n",
        "The next step will be to divide the data into test and train sets. We want to check the performance of the model that we built. For this purpose, we always split (both input and output data) the given data into **train set** which will be used to train the model, and **test set** which will be used to check how accurately the model is predicting outcomes.\n",
        "\n",
        "This is achieved using `train_test_split` function provided in the `model_selection class of sklearn` module.\n",
        "\n",
        "By passing our X and y variables into the train_test_split method, we are able to capture the splits in data by assigning 4 variables to the result.\n",
        "\n",
        "* **X_train:** independent/input feature data for training the model\n",
        "* **y_train:** dependent/output feature data for training the model\n",
        "* **X_test:** independent/input feature data for testing the model; will be used to predict the output values\n",
        "* **y_test:** original dependent/output values of X_test; We will compare this values with our predicted values to check the performance of our built model.\n",
        "* **test_size = 0.20:** 20% of the data will go for test set and 80% of the data will go for train set\n",
        "* **random_state = 42:** this is just for code reproducability. It will fix the split i.e. there will be the same data in train and test sets each time you run the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z801Zj_1fdm"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOFCOrnw1uz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef326c2-c998-4563-c976-09bbacb6238c"
      },
      "source": [
        "# find the number of input features\n",
        "X_train.shape[1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIQzwLyF11WZ"
      },
      "source": [
        "# Model Building\n",
        "Now that we have our data fully processed and split into training and testing datasets, we can begin building a neural network to solve this classification problem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "capBwltU12Tn"
      },
      "source": [
        "# Imports\n",
        "import tensorflow as tf  # Importing the TensorFlow Library\n",
        "from tensorflow import keras  # Import Keras from TensorFlow\n",
        "\n",
        "from tensorflow.keras import Sequential \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5925Ncc2CYd"
      },
      "source": [
        "## Model Creation/ Definition\n",
        "We create a Sequential model and add layers one at a time until we are happy with our network architecture.\n",
        "\n",
        "The first thing to get right is to ensure the input layer has the right number of input features.\n",
        "\n",
        "Since this is a binary classification problem, we will use a sigmoid activation function in the final layer of our network.\n",
        "\n",
        "**Sigmoid is commonly used in the output layer. This is because it helps in giving a probability(value between 0 and 1) which is useful in Binary Classification.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu5u9f0y2Hl5"
      },
      "source": [
        "### Our model architecture\n",
        "For our model, we'll be considering the following:\n",
        "\n",
        "* Input = the no. of features in X_train = 4\n",
        "* No. of neurons/units in first Dense layer = 32\n",
        "* No. of neurons/units in second Dense layer = 16\n",
        "* No. of neurons/units in third Dense layer = 8\n",
        "* No. of neurons/units in output layer = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwcxpTV62ML2"
      },
      "source": [
        "# Building the model\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))   \n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))     "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGNc9SK12YY3"
      },
      "source": [
        "* The above code creates a Neural Network that has 4 layers. \n",
        "\n",
        "* The **last node** uses the **sigmoid activation function** that will squeeze all the values between 0 and 1.\n",
        "\n",
        "* The other layers use **ReLU (Rectified Linear Units)** as the activation function. ReLU is a half rectified function; that is, for all the inputs less than 0 (e.g. -120,-6.7, -0.0344, 0) the value is 0 while for anything positive (e.g. 10,15, 34) the value is retained. \n",
        "\n",
        "* One output unit is used since for each record values in X, a probability will be predicted. If it is high, then the note is genuine. If it is less, then the note is not genuine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju1uPVJs2rtu"
      },
      "source": [
        "## Model Compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLqBhVE42wiE"
      },
      "source": [
        "# Compiling the model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "optimizer = RMSprop(0.001)  # Here, we have set our learning rate as 0.001\n",
        "model.compile(loss='binary_crossentropy', optimizer= optimizer , metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsTAIyQL24I9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae1eb35-4a95-4896-945d-046037379ca1"
      },
      "source": [
        "# printing the summary of the model\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 32)                160       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 833\n",
            "Trainable params: 833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7iNySlf2-sF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "c06a4f93-d479-401f-83f7-7523c19e4440"
      },
      "source": [
        "# plotting the model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKqFKUD_3HJk"
      },
      "source": [
        "## Model Training\n",
        "The model is initially trained for **200 epochs** with a **batch size of 10**. \n",
        "Both epochs and batch size are hyperparameters that can be modified to optimise the model.\n",
        "\n",
        "**validation_split:** Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. \n",
        "The val_loss and val_accuracy that you can see below are calculated with this validation data.\n",
        "\n",
        "\n",
        "**verbose:** Verbose is just for printing purposes, for making the output more readable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVzuSw6e3MSn"
      },
      "source": [
        "### History\n",
        "Notice that we're saving the trained model to a variable **history**. \n",
        "\n",
        "When running a model, Tensorflow Keras maintains a so-called History object in the background. This object keeps all loss values and other metric values in memory so that they can be used for visualizations.\n",
        "\n",
        "The history object is the output of the fit operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UitPpc2Q3QxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a3bf37-1b44-432a-9549-3778bf66c83c"
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=200, batch_size=10, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 0.5894 - accuracy: 0.5857 - val_loss: 0.4644 - val_accuracy: 0.8977\n",
            "Epoch 2/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.9300 - val_loss: 0.3452 - val_accuracy: 0.9830\n",
            "Epoch 3/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.2389 - accuracy: 0.9771 - val_loss: 0.1011 - val_accuracy: 0.9943\n",
            "Epoch 4/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9886 - val_loss: 0.0356 - val_accuracy: 0.9943\n",
            "Epoch 5/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9971 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 7/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 9.5396e-04 - accuracy: 1.0000 - val_loss: 7.0706e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9986 - val_loss: 4.9143e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 6.5536e-04 - accuracy: 1.0000 - val_loss: 3.0085e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.7111e-04 - accuracy: 1.0000 - val_loss: 2.1733e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7690e-04 - accuracy: 1.0000 - val_loss: 1.0507e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2815e-04 - accuracy: 1.0000 - val_loss: 8.5377e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 8.7571e-05 - accuracy: 1.0000 - val_loss: 6.1126e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 4.4249e-05 - accuracy: 1.0000 - val_loss: 2.5247e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.3758e-05 - accuracy: 1.0000 - val_loss: 2.3753e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7354e-05 - accuracy: 1.0000 - val_loss: 3.1335e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2325e-05 - accuracy: 1.0000 - val_loss: 4.6897e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 7.1294e-06 - accuracy: 1.0000 - val_loss: 4.3882e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.5584e-06 - accuracy: 1.0000 - val_loss: 3.3347e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9640e-06 - accuracy: 1.0000 - val_loss: 8.2664e-07 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.5858e-06 - accuracy: 1.0000 - val_loss: 1.8300e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 5.9101e-07 - accuracy: 1.0000 - val_loss: 1.6941e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.2183e-07 - accuracy: 1.0000 - val_loss: 1.7811e-07 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.4860e-07 - accuracy: 1.0000 - val_loss: 8.2744e-08 - val_accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3445e-07 - accuracy: 1.0000 - val_loss: 4.5931e-08 - val_accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.4920e-07 - accuracy: 1.0000 - val_loss: 7.8589e-08 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 5.1287e-08 - accuracy: 1.0000 - val_loss: 6.9526e-08 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.8182e-08 - accuracy: 1.0000 - val_loss: 6.8981e-08 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0436e-08 - accuracy: 1.0000 - val_loss: 1.0902e-08 - val_accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4616e-08 - accuracy: 1.0000 - val_loss: 1.5368e-08 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 8.6762e-09 - accuracy: 1.0000 - val_loss: 1.2435e-08 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 6.2665e-09 - accuracy: 1.0000 - val_loss: 1.3733e-08 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 4.2011e-09 - accuracy: 1.0000 - val_loss: 1.1662e-08 - val_accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.7890e-09 - accuracy: 1.0000 - val_loss: 1.0246e-08 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.6775e-09 - accuracy: 1.0000 - val_loss: 4.6235e-09 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.4035e-09 - accuracy: 1.0000 - val_loss: 6.9094e-09 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9883e-09 - accuracy: 1.0000 - val_loss: 4.1035e-09 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.6738e-09 - accuracy: 1.0000 - val_loss: 5.2044e-09 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4455e-09 - accuracy: 1.0000 - val_loss: 4.8924e-09 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3374e-09 - accuracy: 1.0000 - val_loss: 4.4205e-09 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1077e-09 - accuracy: 1.0000 - val_loss: 3.5412e-09 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 9.9980e-10 - accuracy: 1.0000 - val_loss: 3.1683e-09 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 9.9464e-10 - accuracy: 1.0000 - val_loss: 3.2097e-09 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 9.2700e-10 - accuracy: 1.0000 - val_loss: 5.8941e-09 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 8.0900e-10 - accuracy: 1.0000 - val_loss: 2.7860e-09 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 7.2240e-10 - accuracy: 1.0000 - val_loss: 2.0683e-09 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 7.9019e-10 - accuracy: 1.0000 - val_loss: 3.6309e-09 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 6.7873e-10 - accuracy: 1.0000 - val_loss: 1.8892e-09 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 6.1063e-10 - accuracy: 1.0000 - val_loss: 1.7597e-09 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 5.6405e-10 - accuracy: 1.0000 - val_loss: 1.7237e-09 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 5.5620e-10 - accuracy: 1.0000 - val_loss: 1.3741e-09 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 5.3536e-10 - accuracy: 1.0000 - val_loss: 1.3648e-09 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 5.1853e-10 - accuracy: 1.0000 - val_loss: 1.4192e-09 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 5.1675e-10 - accuracy: 1.0000 - val_loss: 1.2366e-09 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 5.7159e-10 - accuracy: 1.0000 - val_loss: 1.8261e-09 - val_accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 4.6424e-10 - accuracy: 1.0000 - val_loss: 1.4288e-09 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 4.4640e-10 - accuracy: 1.0000 - val_loss: 1.1202e-09 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.9738e-10 - accuracy: 1.0000 - val_loss: 1.0394e-09 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.8350e-10 - accuracy: 1.0000 - val_loss: 9.7108e-10 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 3.8074e-10 - accuracy: 1.0000 - val_loss: 9.3415e-10 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.8249e-10 - accuracy: 1.0000 - val_loss: 9.1158e-10 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.6837e-10 - accuracy: 1.0000 - val_loss: 8.8741e-10 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.6966e-10 - accuracy: 1.0000 - val_loss: 8.6828e-10 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.8427e-10 - accuracy: 1.0000 - val_loss: 8.5821e-10 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.5054e-10 - accuracy: 1.0000 - val_loss: 8.1015e-10 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.6238e-10 - accuracy: 1.0000 - val_loss: 7.8815e-10 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.4426e-10 - accuracy: 1.0000 - val_loss: 7.6292e-10 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.5140e-10 - accuracy: 1.0000 - val_loss: 7.5781e-10 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 4.1699e-10 - accuracy: 1.0000 - val_loss: 1.2810e-09 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.2415e-10 - accuracy: 1.0000 - val_loss: 9.6053e-10 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.1291e-10 - accuracy: 1.0000 - val_loss: 8.8951e-10 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.9741e-10 - accuracy: 1.0000 - val_loss: 7.9126e-10 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.4190e-10 - accuracy: 1.0000 - val_loss: 7.5094e-10 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.3626e-10 - accuracy: 1.0000 - val_loss: 7.1870e-10 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.3201e-10 - accuracy: 1.0000 - val_loss: 7.0531e-10 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.3196e-10 - accuracy: 1.0000 - val_loss: 7.2855e-10 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.3204e-10 - accuracy: 1.0000 - val_loss: 7.4603e-10 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.3213e-10 - accuracy: 1.0000 - val_loss: 7.5651e-10 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2545e-10 - accuracy: 1.0000 - val_loss: 7.7494e-10 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2805e-10 - accuracy: 1.0000 - val_loss: 6.4894e-10 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2867e-10 - accuracy: 1.0000 - val_loss: 6.7103e-10 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.3978e-10 - accuracy: 1.0000 - val_loss: 5.8021e-10 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 2.4452e-10 - accuracy: 1.0000 - val_loss: 6.2321e-10 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.3982e-10 - accuracy: 1.0000 - val_loss: 5.4511e-10 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.9623e-10 - accuracy: 1.0000 - val_loss: 1.0794e-09 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2507e-10 - accuracy: 1.0000 - val_loss: 7.4443e-10 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0821e-10 - accuracy: 1.0000 - val_loss: 6.0338e-10 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0758e-10 - accuracy: 1.0000 - val_loss: 5.1365e-10 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0772e-10 - accuracy: 1.0000 - val_loss: 4.4951e-10 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.1194e-10 - accuracy: 1.0000 - val_loss: 4.0197e-10 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.1465e-10 - accuracy: 1.0000 - val_loss: 4.3817e-10 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.1587e-10 - accuracy: 1.0000 - val_loss: 3.9390e-10 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2789e-10 - accuracy: 1.0000 - val_loss: 3.5867e-10 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.4827e-10 - accuracy: 1.0000 - val_loss: 3.9531e-10 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.3751e-10 - accuracy: 1.0000 - val_loss: 3.6047e-10 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.5095e-10 - accuracy: 1.0000 - val_loss: 3.3183e-10 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 3.1512e-10 - accuracy: 1.0000 - val_loss: 6.6722e-10 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0367e-10 - accuracy: 1.0000 - val_loss: 5.2636e-10 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9853e-10 - accuracy: 1.0000 - val_loss: 4.4484e-10 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9553e-10 - accuracy: 1.0000 - val_loss: 3.8930e-10 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9495e-10 - accuracy: 1.0000 - val_loss: 3.4848e-10 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9825e-10 - accuracy: 1.0000 - val_loss: 3.1687e-10 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0561e-10 - accuracy: 1.0000 - val_loss: 2.9159e-10 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 2.1320e-10 - accuracy: 1.0000 - val_loss: 2.7070e-10 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "70/70 [==============================] - 1s 7ms/step - loss: 2.0913e-10 - accuracy: 1.0000 - val_loss: 3.0458e-10 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.1330e-10 - accuracy: 1.0000 - val_loss: 2.8202e-10 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2817e-10 - accuracy: 1.0000 - val_loss: 2.6331e-10 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.4248e-10 - accuracy: 1.0000 - val_loss: 2.4721e-10 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.5096e-10 - accuracy: 1.0000 - val_loss: 5.5865e-10 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9651e-10 - accuracy: 1.0000 - val_loss: 4.3951e-10 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8804e-10 - accuracy: 1.0000 - val_loss: 3.7177e-10 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8701e-10 - accuracy: 1.0000 - val_loss: 3.2701e-10 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8480e-10 - accuracy: 1.0000 - val_loss: 2.9396e-10 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8515e-10 - accuracy: 1.0000 - val_loss: 2.6853e-10 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8812e-10 - accuracy: 1.0000 - val_loss: 2.4818e-10 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9363e-10 - accuracy: 1.0000 - val_loss: 2.3142e-10 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9480e-10 - accuracy: 1.0000 - val_loss: 2.1738e-10 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0173e-10 - accuracy: 1.0000 - val_loss: 2.4504e-10 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9546e-10 - accuracy: 1.0000 - val_loss: 2.2943e-10 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0133e-10 - accuracy: 1.0000 - val_loss: 2.1610e-10 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0993e-10 - accuracy: 1.0000 - val_loss: 2.0463e-10 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.1255e-10 - accuracy: 1.0000 - val_loss: 1.9466e-10 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.3053e-10 - accuracy: 1.0000 - val_loss: 1.8583e-10 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.3510e-10 - accuracy: 1.0000 - val_loss: 2.0988e-10 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.1894e-10 - accuracy: 1.0000 - val_loss: 1.9914e-10 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2871e-10 - accuracy: 1.0000 - val_loss: 1.8974e-10 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.3565e-10 - accuracy: 1.0000 - val_loss: 1.8139e-10 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.6666e-10 - accuracy: 1.0000 - val_loss: 4.1019e-10 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9092e-10 - accuracy: 1.0000 - val_loss: 3.4005e-10 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8386e-10 - accuracy: 1.0000 - val_loss: 2.9622e-10 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8249e-10 - accuracy: 1.0000 - val_loss: 2.6528e-10 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7983e-10 - accuracy: 1.0000 - val_loss: 2.4204e-10 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8132e-10 - accuracy: 1.0000 - val_loss: 2.2370e-10 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8119e-10 - accuracy: 1.0000 - val_loss: 2.0871e-10 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8310e-10 - accuracy: 1.0000 - val_loss: 1.9621e-10 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8415e-10 - accuracy: 1.0000 - val_loss: 1.8560e-10 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8694e-10 - accuracy: 1.0000 - val_loss: 1.7650e-10 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9121e-10 - accuracy: 1.0000 - val_loss: 1.6855e-10 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9755e-10 - accuracy: 1.0000 - val_loss: 1.6155e-10 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0221e-10 - accuracy: 1.0000 - val_loss: 1.5532e-10 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0726e-10 - accuracy: 1.0000 - val_loss: 1.4976e-10 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.1241e-10 - accuracy: 1.0000 - val_loss: 1.6962e-10 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9808e-10 - accuracy: 1.0000 - val_loss: 1.6247e-10 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0677e-10 - accuracy: 1.0000 - val_loss: 1.5620e-10 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.1441e-10 - accuracy: 1.0000 - val_loss: 1.5064e-10 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2229e-10 - accuracy: 1.0000 - val_loss: 1.4562e-10 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2935e-10 - accuracy: 1.0000 - val_loss: 1.4105e-10 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 2.3393e-10 - accuracy: 1.0000 - val_loss: 1.3689e-10 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.4762e-10 - accuracy: 1.0000 - val_loss: 1.3307e-10 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.3748e-10 - accuracy: 1.0000 - val_loss: 2.8124e-10 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7891e-10 - accuracy: 1.0000 - val_loss: 2.4700e-10 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7650e-10 - accuracy: 1.0000 - val_loss: 2.2300e-10 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7550e-10 - accuracy: 1.0000 - val_loss: 2.0482e-10 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7466e-10 - accuracy: 1.0000 - val_loss: 1.9040e-10 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7440e-10 - accuracy: 1.0000 - val_loss: 1.7875e-10 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7576e-10 - accuracy: 1.0000 - val_loss: 1.6897e-10 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7584e-10 - accuracy: 1.0000 - val_loss: 1.6068e-10 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7726e-10 - accuracy: 1.0000 - val_loss: 1.5354e-10 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7962e-10 - accuracy: 1.0000 - val_loss: 1.4727e-10 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8183e-10 - accuracy: 1.0000 - val_loss: 1.4175e-10 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8422e-10 - accuracy: 1.0000 - val_loss: 1.3684e-10 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8638e-10 - accuracy: 1.0000 - val_loss: 1.3243e-10 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8955e-10 - accuracy: 1.0000 - val_loss: 1.2843e-10 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9303e-10 - accuracy: 1.0000 - val_loss: 1.2479e-10 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9774e-10 - accuracy: 1.0000 - val_loss: 1.2148e-10 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0512e-10 - accuracy: 1.0000 - val_loss: 1.1847e-10 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0740e-10 - accuracy: 1.0000 - val_loss: 1.3308e-10 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9496e-10 - accuracy: 1.0000 - val_loss: 1.2896e-10 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.9795e-10 - accuracy: 1.0000 - val_loss: 1.2529e-10 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0345e-10 - accuracy: 1.0000 - val_loss: 1.2193e-10 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.0604e-10 - accuracy: 1.0000 - val_loss: 1.1886e-10 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.1268e-10 - accuracy: 1.0000 - val_loss: 1.1603e-10 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.1970e-10 - accuracy: 1.0000 - val_loss: 1.1342e-10 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 2.2668e-10 - accuracy: 1.0000 - val_loss: 1.1101e-10 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 2.3813e-10 - accuracy: 1.0000 - val_loss: 1.0877e-10 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.8844e-10 - accuracy: 1.0000 - val_loss: 1.1634e-10 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.3647e-10 - accuracy: 1.0000 - val_loss: 1.1338e-10 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4169e-10 - accuracy: 1.0000 - val_loss: 1.1066e-10 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4421e-10 - accuracy: 1.0000 - val_loss: 1.0813e-10 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.5190e-10 - accuracy: 1.0000 - val_loss: 1.0578e-10 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.5572e-10 - accuracy: 1.0000 - val_loss: 1.0358e-10 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.6270e-10 - accuracy: 1.0000 - val_loss: 1.0155e-10 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.6703e-10 - accuracy: 1.0000 - val_loss: 9.9730e-11 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7354e-10 - accuracy: 1.0000 - val_loss: 9.8010e-11 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.7441e-10 - accuracy: 1.0000 - val_loss: 1.9348e-10 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1618e-10 - accuracy: 1.0000 - val_loss: 1.7407e-10 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1385e-10 - accuracy: 1.0000 - val_loss: 1.6019e-10 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1425e-10 - accuracy: 1.0000 - val_loss: 1.4977e-10 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1485e-10 - accuracy: 1.0000 - val_loss: 1.4139e-10 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1486e-10 - accuracy: 1.0000 - val_loss: 1.3466e-10 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1554e-10 - accuracy: 1.0000 - val_loss: 1.2887e-10 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1571e-10 - accuracy: 1.0000 - val_loss: 1.2387e-10 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1673e-10 - accuracy: 1.0000 - val_loss: 1.1946e-10 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1735e-10 - accuracy: 1.0000 - val_loss: 1.1555e-10 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1834e-10 - accuracy: 1.0000 - val_loss: 1.1202e-10 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.1896e-10 - accuracy: 1.0000 - val_loss: 1.0885e-10 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 1.2073e-10 - accuracy: 1.0000 - val_loss: 1.0599e-10 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1Qemmg83t9U"
      },
      "source": [
        "## Model Evaluation\n",
        "Evaluating the model requires that you first choose a separate dataset used to evaluate the model. This should be data not used in the training process i.e. the X_test.\n",
        "\n",
        "Now, let us use the trained model to predict the probability values for the new data set - The test set we had initially created. The below code passes the X_test and y_test to the trained model and gives out the probability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RakwKTN63xXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9fb6ea-0b24-484e-dec1-7b0880bd0852"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 1.5296e-07 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5296247113383288e-07, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxzypkQU36Ct"
      },
      "source": [
        "### Model Accuracy\n",
        "Now, we'll use the history object created above to plot the Accuracy and Loss throughout the training process.\n",
        "\n",
        "You can think of history.history as a Python dictionary from which the values can be obtained by specifying a key within square brackets.\n",
        "\n",
        "For eg. `history.history['accuracy']` will give the train accuracy throughout the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEaLK66a37wr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "72078143-a8a2-4a46-fbcf-13f1cf3004e5"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAi1mZIY4FLo"
      },
      "source": [
        "### Model Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q68G3cc4G_u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "157b2909-286f-44ed-fd8e-cf2369a08f28"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xdZX3v8c93XyaTG7mjkAATlSDxhFwYgm28gFALSJMKARKqkGLlhaco1KoFVKB4bKtEa08PVVEQRTRSFE7UcGJDxcuhYCYhIAlEkhBgAoQQIBcgyczk1z/WmsmeycxkclmzJ1nf94t5sfe67P2bNZP9ned51nqWIgIzM8uvQrULMDOz6nIQmJnlnIPAzCznHARmZjnnIDAzyzkHgZlZzjkIzLohqU5SSCr1YNs5kn7bG3WZHUgOAjtkSForaYekkR2WP5x+mNdVp7K9CxSz3uYgsEPNU8Ds1ieSJgADqleOWd/nILBDze3ARRXPLwa+V7mBpCGSvidpg6SnJX1OUiFdV5Q0V9JLktYAH+hk31skPS9pnaT/Jam4PwVLOlLSfEkvS1ol6aMV66ZKapC0WdJ6SV9Nl9dK+r6kjZJelbRY0pv2pw7LLweBHWoeBA6TdHz6AT0L+H6Hbf4VGAK8BXgvSXD8Zbruo8DZwGSgHpjZYd/bgGbgbek27wf+aj9rngc0Akem7/cPkt6XrvsX4F8i4jDgrcCd6fKL0+/hKGAEcBnwxn7WYTnlILBDUWur4E+Ax4F1rSsqwuHqiNgSEWuBrwAfTjc5H/haRDwbES8D/1ix75uAs4ArI+K1iHgR+Of09faJpKOAacDfRcS2iFgGfJtdrZom4G2SRkbE1oh4sGL5COBtEdESEUsiYvO+1mH55iCwQ9HtwIXAHDp0CwEjgTLwdMWyp4HR6eMjgWc7rGt1TLrv82l3zKvAN4HD96PWI4GXI2JLF/V8BBgHPJF2/5ydLr8dWAjMk/ScpC9LKu9HHZZjDgI75ETE0ySDxmcBP+mw+iWSv6aPqVh2NLtaDc+TdLdUrmv1LLAdGBkRQ9OvwyLiHftR7nPAcEmDO6snIp6MiNkkYfMl4C5JAyOiKSL+PiLGA39M0p11EWb7wEFgh6qPAO+LiNcqF0ZEC0k/+xclDZZ0DPBJdo0j3Al8QtIYScOAqyr2fR74BfAVSYdJKkh6q6T37kVd/dKB3lpJtSQf+A8A/5guOyGt/fsAkj4kaVRE7AReTV9jp6RTJU1Iu7o2k4Tbzr2ow6yNg8AOSRGxOiIaulj9ceA1YA3wW+AHwK3pum+RdLk8Aixl9xbFRUANsAJ4BbgLOGIvSttKMqjb+vU+ktNd60haB3cD10XEonT7M4DlkraSDBzPiog3gDen772ZZBzkVyTdRWZ7Tb4xjZlZvrlFYGaWcw4CM7OccxCYmeWcg8DMLOcOupkQR44cGXV1ddUuw8zsoLJkyZKXImJUZ+sOuiCoq6ujoaGrswLNzKwzkp7uap27hszMcs5BYGaWc5kGgaQzJK1M51i/qottzpe0QtJyST/Ish4zM9tdZmME6RwoN5FMBdwILJY0PyJWVGxzLHA1MC0iXpG0P7M4mtlBpqmpicbGRrZt21btUg4ZtbW1jBkzhnK555PRZjlYPBVYFRFrACTNA2aQzNHS6qPATRHxCkA6v7uZ5URjYyODBw+mrq4OSdUu56AXEWzcuJHGxkbGjh3b4/2y7BoaTft53RvZNcd6q3HAOEn/X9KDks7o7IUkXZrerq9hw4YNGZVrZr1t27ZtjBgxwiFwgEhixIgRe93CqvZgcQk4FjiFZAbGb0ka2nGjiLg5Iuojon7UqE5PgzWzg5RD4MDal+OZZRCso/0NPsZQccvAVCMwP73JxlPAH0iC4YBbvPZlvvKLlTS3eMp2M7NKWQbBYuBYSWMl1ZDc13V+h23uIWkNIGkkSVfRmiyKefiZV/jX/1zF9mYHgZklNm7cyKRJk5g0aRJvfvObGT16dNvzHTt2dLtvQ0MDn/jEJ3qp0mxlNlgcEc2SLie5yUcRuDUilku6AWiIiPnpuvdLWgG0AJ+OiI1Z1FMuJpnX5BaBmaVGjBjBsmXLALj++usZNGgQn/rUp9rWNzc3Uyp1/jFZX19PfX19r9SZtUynmIiIBcCCDsuurXgcJLcJ/GSWdcCuINjhFoGZdWPOnDnU1tby8MMPM23aNGbNmsUVV1zBtm3b6N+/P9/5znc47rjjuP/++5k7dy4/+9nPuP7663nmmWdYs2YNzzzzDFdeeeVB1Vo46OYa2lc1rUHgFoFZn/T3P13Oiuc2H9DXHH/kYVz3Z+/Y6/0aGxt54IEHKBaLbN68md/85jeUSiUWLVrENddcw49//OPd9nniiSf45S9/yZYtWzjuuOP42Mc+tlfn8ldTfoKg1No15Ftzmln3zjvvPIrFIgCbNm3i4osv5sknn0QSTU1Nne7zgQ98gH79+tGvXz8OP/xw1q9fz5gxY3qz7H2WmyDwGIFZ37Yvf7lnZeDAgW2PP//5z3Pqqady9913s3btWk455ZRO9+nXr1/b42KxSHNzc9ZlHjDVvo6g15SLybm1HiMws72xadMmRo9OroW97bbbqltMRvITBCWPEZjZ3vvMZz7D1VdfzeTJkw+qv/L3hpITdw4e9fX1sS83pnlg1Utc+O2H+NGl7+Tkt4zIoDIz21uPP/44xx9/fLXLOOR0dlwlLYmITs93zV2LwIPFZmbt5ScIPFhsZtapHAVBMljsKSbMzNrLTRD0K7lFYGbWmdwEgbuGzMw65yAwM8u53AWBLygzs1annnoqCxcubLfsa1/7Gh/72Mc63f6UU06h9fT1s846i1dffXW3ba6//nrmzp3b7fvec889rFix66691157LYsWLdrb8g+Y3ARBTdsFZT591MwSs2fPZt68ee2WzZs3j9mzZ+9x3wULFjB06G43VOyRjkFwww03cPrpp+/Tax0I+QkCdw2ZWQczZ87k5z//edtNaNauXctzzz3HD3/4Q+rr63nHO97Bdddd1+m+dXV1vPTSSwB88YtfZNy4cbzrXe9i5cqVbdt861vf4qSTTmLixImce+65vP766zzwwAPMnz+fT3/600yaNInVq1czZ84c7rrrLgDuu+8+Jk+ezIQJE7jkkkvYvn172/tdd911TJkyhQkTJvDEE08csOOQo0nnktNHm9w1ZNY33XsVvPD7A/uab54AZ/5Tl6uHDx/O1KlTuffee5kxYwbz5s3j/PPP55prrmH48OG0tLRw2mmn8eijj3LCCSd0+hpLlixh3rx5LFu2jObmZqZMmcKJJ54IwDnnnMNHP/pRAD73uc9xyy238PGPf5zp06dz9tlnM3PmzHavtW3bNubMmcN9993HuHHjuOiii/j617/OlVdeCcDIkSNZunQp//Zv/8bcuXP59re/fSCOUn5aBMWCkDzXkJm1V9k91NotdOeddzJlyhQmT57M8uXL23XjdPSb3/yGD37wgwwYMIDDDjuM6dOnt6177LHHePe7382ECRO44447WL58ebe1rFy5krFjxzJu3DgALr74Yn7961+3rT/nnHMAOPHEE1m7du2+fsu7yU2LQBLlYsFBYNZXdfOXe5ZmzJjB3/zN37B06VJef/11hg8fzty5c1m8eDHDhg1jzpw5bNu2bZ9ee86cOdxzzz1MnDiR2267jfvvv3+/am2d6vpAT3OdmxYBQL9igaZmDxab2S6DBg3i1FNP5ZJLLmH27Nls3ryZgQMHMmTIENavX8+9997b7f7vec97uOeee3jjjTfYsmULP/3pT9vWbdmyhSOOOIKmpibuuOOOtuWDBw9my5Ytu73Wcccdx9q1a1m1ahUAt99+O+9973sP0HfatVwFQblU8GCxme1m9uzZPPLII8yePZuJEycyefJk3v72t3PhhRcybdq0bvedMmUKF1xwARMnTuTMM8/kpJNOalv3hS98gZNPPplp06bx9re/vW35rFmzuPHGG5k8eTKrV69uW15bW8t3vvMdzjvvPCZMmEChUOCyyy478N9wB7mZhhrg5H9YxCnjDudLMzsf9DGz3uVpqLPhaai7US66RWBm1lGugqCm5MFiM7OO8hUEbhGY9TkHW/d0X7cvxzPTIJB0hqSVklZJuqqT9XMkbZC0LP36qyzrKRcLnmvIrA+pra1l48aNDoMDJCLYuHEjtbW1e7VfZtcRSCoCNwF/AjQCiyXNj4iOV2b8KCIuz6qOSuWifKtKsz5kzJgxNDY2smHDhmqXcsiora1lzJgxe7VPlheUTQVWRcQaAEnzgBlA15foZcxjBGZ9S7lcZuzYsdUuI/ey7BoaDTxb8bwxXdbRuZIelXSXpKM6eyFJl0pqkNSwP385+KwhM7PdVXuw+KdAXUScAPwH8N3ONoqImyOiPiLqR40atc9vVuMxAjOz3WQZBOuAyr/wx6TL2kTExojYnj79NnBihvW4RWBm1oksg2AxcKyksZJqgFnA/MoNJB1R8XQ68HiG9VBTKniw2Mysg8wGiyOiWdLlwEKgCNwaEcsl3QA0RMR84BOSpgPNwMvAnKzqAZ8+ambWmUynoY6IBcCCDsuurXh8NXB1ljVUqinJZw2ZmXVQ7cHiXuUxAjOz3eUqCGqKBd+q0sysg1wFQdmDxWZmu8lXEKS3qvS8JmZmu+QqCGqKAnCrwMysQn6CYNV9nLbqHyjR7AFjM7MK+QmCFx/n+Od+Qn92OAjMzCrkJwjK/QGoZYcvKjMzq5C/INB2X1RmZlYhd0GQdA15sNjMrFWOgmAAAP3Z7jECM7MKOQqC1jGCJo8RmJlVyFEQpC0CjxGYmbWTnyAo1QLJWUOeb8jMbJf8BEHbYPF2DxabmVXIURC0dg3tYEdLS5WLMTPrO3IUBJUXlLlFYGbWKkdBkLQIan36qJlZO/kJgmKZUIH+8lxDZmaV8hMEElHqT3+2+zoCM7MK+QkCgHJ/zz5qZtZBzoJgALXawQ6fPmpm1iZfQVCq9WCxmVkHuQoC1Qygv+9HYGbWTq6CgHJ/nzVkZtZBpkEg6QxJKyWtknRVN9udKykk1WdaT3kAAzzpnJlZO5kFgaQicBNwJjAemC1pfCfbDQauAB7KqpY25f70p4kmX1lsZtYmyxbBVGBVRKyJiB3APGBGJ9t9AfgSsC3DWhJp15DnGjIz2yXLIBgNPFvxvDFd1kbSFOCoiPh5dy8k6VJJDZIaNmzYsO8VlftT6wvKzMzaqdpgsaQC8FXgb/e0bUTcHBH1EVE/atSofX/T8gAHgZlZB1kGwTrgqIrnY9JlrQYD/wO4X9Ja4J3A/EwHjMv9k9lHPVhsZtYmyyBYDBwraaykGmAWML91ZURsioiREVEXEXXAg8D0iGjIrKLyAMo009zUlNlbmJkdbDILgohoBi4HFgKPA3dGxHJJN0iantX7diu9XWU0vVGVtzcz64tKWb54RCwAFnRYdm0X256SZS1A281p5CAwM2uTsyuLk5vTqMVBYGbWKmdBkLQICs3ZX7JgZnawyFkQJC2CQrNbBGZmrXIWBMlgcbHFLQIzs1Y5C4KkRVD0GIGZWZucBUEyRlByi8DMrE3OgiBtEezcXuVCzMz6jpwFgVsEZmYd5SsI0iuLy7GNCN+TwMwM8hYEaddQ/9hB804HgZkZ5C0ISv0IRK22+77FZmapfAWBRHOxllqafE8CM7NUvoIAaCn0S+5J4CAwMwNyGARRKFKihe0OAjMzIIdBQKFMiRbfpczMLJW7IAiVKKnFXUNmZqn8BUGxTJlmB4GZWSp3QUCh5K4hM7MKOQ2CnW4RmJml8hcExTIldw2ZmbXJXRDIZw2ZmbWTuyCgWKLss4bMzNrkLghULFPEQWBm1qpHQSDpCkmHKXGLpKWS3p91cVlQsUzZXUNmZm162iK4JCI2A+8HhgEfBv5pTztJOkPSSkmrJF3VyfrLJP1e0jJJv5U0fq+q3weFYjpG4BaBmRnQ8yBQ+v+zgNsjYnnFss53kIrATcCZwHhgdicf9D+IiAkRMQn4MvDVHle+j1RyEJiZVeppECyR9AuSIFgoaTCwp0/SqcCqiFgTETuAecCMyg3SVkargUDmd4splNIri901ZGYGQKmH230EmASsiYjXJQ0H/nIP+4wGnq143gic3HEjSX8NfBKoAd7X2QtJuhS4FODoo4/uYcmdKxTLFNnp2UfNzFI9bRH8EbAyIl6V9CHgc8CmA1FARNwUEW8F/i593c62uTki6iOiftSoUfv1fiqUffqomVmFngbB14HXJU0E/hZYDXxvD/usA46qeD4mXdaVecCf97CefVcsUabFt6o0M0v1NAiaIyJI+vj/T0TcBAzewz6LgWMljZVUA8wC5lduIOnYiqcfAJ7sYT37rlCmLE8xYWbWqqdjBFskXU1y2ui7JRWAcnc7RESzpMuBhUARuDUilku6AWiIiPnA5ZJOB5qAV4CL9/Ub6bFCiaInnTMza9PTILgAuJDkeoIXJB0N3LinnSJiAbCgw7JrKx5fsRe1HhhFzzVkZlapR11DEfECcAcwRNLZwLaI2NMYQd9UKHn2UTOzCj2dYuJ84HfAecD5wEOSZmZZWGbSFoFPHzUzS/S0a+izwEkR8SKApFHAIuCurArLTKFMgaCpuanalZiZ9Qk9PWuo0BoCqY17sW/fUigC0NK8o8qFmJn1DT1tEfw/SQuBH6bPL6DDIPBBo5ic7LSzyS0CMzPoYRBExKclnQtMSxfdHBF3Z1dWhgpJELS0OAjMzKDnLQIi4sfAjzOspXekLYLwGIGZGbCHIJC0hc5nBBUQEXFYJlVlKR0j2OkWgZkZsIcgiIg9TSNx8Em7hhwEZmaJg/PMn/3ROljsriEzMyCPQVBIGkHR4tNHzcwg10HgFoGZGeQxCFrPGmpprnIhZmZ9Q/6CIB0sLkYLzZ6B1Mwsh0FQTLqGSr6BvZkZkMcgSFsEZbXQ1NzZJRJmZvmSwyBIWgRFdrK9paXKxZiZVV/+giAdLPbNaczMEvkLgrRFUKbFQWBmRh6DoK1F4PsWm5lBHoPALQIzs3ZyGwRFB4GZGZDHIGjtGpKDwMwM8hgErdcR0MJ2jxGYmeUwCHz6qJlZO5kGgaQzJK2UtErSVZ2s/6SkFZIelXSfpGOyrAdou0NZiZ00uUVgZpZdEEgqAjcBZwLjgdmSxnfY7GGgPiJOAO4CvpxVPW0KbhGYmVXKskUwFVgVEWsiYgcwD5hRuUFE/DIiXk+fPgiMybCeROV1BA4CM7NMg2A08GzF88Z0WVc+Atzb2QpJl0pqkNSwYcOG/auqYrDYF5SZmfWRwWJJHwLqgRs7Wx8RN0dEfUTUjxo1av/erFAgkE8fNTNLlTJ87XXAURXPx6TL2pF0OvBZ4L0RsT3DenYplik1t7DdQWBmlmmLYDFwrKSxkmqAWcD8yg0kTQa+CUyPiBczrKW9QtljBGZmqcyCICKagcuBhcDjwJ0RsVzSDZKmp5vdCAwC/l3SMknzu3i5A0rFEv3kMQIzM8i2a4iIWAAs6LDs2orHp2f5/l0qlKkp7HSLwMyMPjJY3OsKJWrkC8rMzCCvQVAsU1PwGIGZGeQ1CNIWgYPAzCyvQVAsUyPPPmpmBnkNgkKJslsEZmZAnoPA1xGYmQF5DYK0a8hBYGaW1yAolJO5hjxGYGaW0yAolt01ZGaWymcQFIqea8jMLJXTIEi6hnxlsZlZXoOgWKYUnobazAzyGgSFUnLPYrcIzMzyGwRFfEGZmRnkNQiKZYo0OwjMzMhrEBTKFMNdQ2ZmkNcgKJYoRgstO4OWnVHtaszMqiqfQZC2CAB3D5lZ7uU0CEoUogVwEJiZ5TMIiiUKrS0CjxOYWc7lMwgKZQeBmVkqn0FQbA2CcNeQmeVePoOgUALwRWVmZuQ8CDwDqZlZxkEg6QxJKyWtknRVJ+vfI2mppGZJM7OspZ1iGYAyzexoaem1tzUz64syCwJJReAm4ExgPDBb0vgOmz0DzAF+kFUdnSokQVDCM5CamZUyfO2pwKqIWAMgaR4wA1jRukFErE3X9e6ncTH5tn2XMjOzbLuGRgPPVjxvTJftNUmXSmqQ1LBhw4b9r6w8AID+2u4gMLPcOygGiyPi5oioj4j6UaNG7f8L9h8GwFC2+joCM8u9LINgHXBUxfMx6bLqS4NgiF7z7SrNLPeyDILFwLGSxkqqAWYB8zN8v56rbBG4a8jMci6zIIiIZuByYCHwOHBnRCyXdIOk6QCSTpLUCJwHfFPS8qzqaaeiReAgMLO8y/KsISJiAbCgw7JrKx4vJuky6l21Q4GkReDTR80s7w6KweIDrlRDlAcyVB4sNjPLZxAA9B/GUHcNmZnlNwjkIDAzA3IcBPQfyjAHgZlZnoNgmMcIzMzIeRAMYasvKDOz3MtxEAzlMLby+vbmaldiZlZVOQ6CYdTQzMubNlW7EjOzqsp1EAC89uoBmM3UzOwglvsg2LFlIy07o8rFmJlVT+6DYFBs5aWt26tcjJlZ9eQ+CIawledefaPKxZiZVU9+g6B14jm9xnOvbqtyMWZm1ZPfIHCLwMwMyHMQ1AyEQpnDS2+wzkFgZjmW3yCQoP8wjqx53S0CM8u1/AYBwLA63lp4juc2OQjMLL/yHQRj6hm740k2vLK12pWYmVVN7oOgJrYz8o3VbGtqqXY1ZmZVkfMgOAmAyYVVPPXSa1UuxsysOvIdBEOOomXA4UwuPMmiFeurXY2ZWVXkOwgkikdP5Y9qnuLnv3++2tWYmVVFvoMAYEw9R7asY8MLjaze4EFjM8sfB8G4MwjEpaWf8fNH3Sows/xxEBx+PJp0IZeUfsFPf/VfrHhuc7UrMjPrVZkGgaQzJK2UtErSVZ2s7yfpR+n6hyTVZVlPl079LKVSiW8Uv8wdt/4LS556qSplmJlVgyKyuSmLpCLwB+BPgEZgMTA7IlZUbPM/gRMi4jJJs4APRsQF3b1ufX19NDQ0HPiCn1jA9gXX0G/zU6zeeQQPDT2LQXX1jD56LG+Uh/LoRjF+9HBOqhvOgJoikg58DWZmGZG0JCLqO12XYRD8EXB9RPxp+vxqgIj4x4ptFqbb/JekEvACMCq6KSqzIADY2cK2R+9h06IbedPWx3dbvSOKbKeGHZRoVpkWSgQi/Y8AxK6A6PhNBOr2ebt16n7b5L32/DpmdujYeOKVnPiBv9qnfbsLgtJ+VdW90cCzFc8bgZO72iYimiVtAkYA7fpmJF0KXApw9NFHZ1UvFIrUTjqX2knnwmsb2fT0Ml547lnKO17hiPIbrH/5FV7d8hrRtI1o3k60NEHATgIi2n3waw8Bq3ZbRzfrgNjD+sz5Vp5mfUHNoOGZvG6WQXDARMTNwM2QtAh65U0HjmDI+NMYMn7XorpeeWMzs96V5WDxOuCoiudj0mWdbpN2DQ0BNmZYk5mZdZBlECwGjpU0VlINMAuY32Gb+cDF6eOZwH92Nz5gZmYHXmZdQ2mf/+XAQqAI3BoRyyXdADRExHzgFuB2SauAl0nCwszMelGmYwQRsQBY0GHZtRWPtwHnZVmDmZl1z1cWm5nlnIPAzCznHARmZjnnIDAzy7nMppjIiqQNwNP7uPtIOly13If01dpc195xXXuvr9Z2qNV1TESM6mzFQRcE+0NSQ1dzbVRbX63Nde0d17X3+mptearLXUNmZjnnIDAzy7m8BcHN1S6gG321Nte1d1zX3uurteWmrlyNEZiZ2e7y1iIwM7MOHARmZjmXmyCQdIaklZJWSbqqinUcJemXklZIWi7pinT59ZLWSVqWfp1VhdrWSvp9+v4N6bLhkv5D0pPp/4f1ck3HVRyTZZI2S7qyWsdL0q2SXpT0WMWyTo+REv87/Z17VNKUXq7rRklPpO99t6Sh6fI6SW9UHLtv9HJdXf7sJF2dHq+Vkv40q7q6qe1HFXWtlbQsXd4rx6ybz4dsf8ci4pD/IpkGezXwFqAGeAQYX6VajgCmpI8HA38AxgPXA5+q8nFaC4zssOzLwFXp46uAL1X55/gCcEy1jhfwHmAK8NiejhFwFnAvye2l3wk81Mt1vR8opY+/VFFXXeV2VThenf7s0n8HjwD9gLHpv9lib9bWYf1XgGt785h18/mQ6e9YXloEU4FVEbEmInYA84AZ1SgkIp6PiKXp4y3A4yT3bu6rZgDfTR9/F/jzKtZyGrA6Ivb1yvL9FhG/Jrl3RqWujtEM4HuReBAYKumI3qorIn4REc3p0wdJ7hLYq7o4Xl2ZAcyLiO0R8RSwiuTfbq/XJknA+cAPs3r/Lmrq6vMh09+xvATBaODZiueN9IEPX0l1wGTgoXTR5Wnz7tbe7oJJBfALSUskXZoue1NEPJ8+fgF4UxXqajWL9v8wq328WnV1jPrS790lJH85thor6WFJv5L07irU09nPri8dr3cD6yPiyYplvXrMOnw+ZPo7lpcg6HMkDQJ+DFwZEZuBrwNvBSYBz5M0S3vbuyJiCnAm8NeS3lO5MpK2aFXON1Zyu9PpwL+ni/rC8dpNNY9RVyR9FmgG7kgXPQ8cHRGTgU8CP5B0WC+W1Cd/dh3Mpv0fHb16zDr5fGiTxe9YXoJgHXBUxfMx6bKqkFQm+SHfERE/AYiI9RHREhE7gW+RYZO4KxGxLv3/i8DdaQ3rW5ua6f9f7O26UmcCSyNifVpj1Y9Xha6OUdV/7yTNAc4G/iL9ACHtetmYPl5C0hc/rrdq6uZnV/XjBSCpBJwD/Kh1WW8es84+H8j4dywvQbAYOFbS2PQvy1nA/GoUkvY93gI8HhFfrVhe2a/3QeCxjvtmXNdASYNbH5MMND5GcpwuTje7GPi/vVlXhXZ/oVX7eHXQ1TGaD1yUntnxTmBTRfM+c5LOAD4DTI+I1yuWj5JUTB+/BTgWWNOLdXX1s5sPzJLUT9LYtK7f9VZdFU4HnoiIxtYFvXXMuvp8IOvfsaxHwfvKF8no+h9IkvyzVazjXSTNukeBZenXWcDtwO/T5fOBI3q5rreQnLHxCLC89RgBI4D7gCeBRcDwKhyzgcBGYEjFsqocL5Iweh5oIumP/UhXx4jkTI6b0t+53wP1vVzXKpL+49bfs2+k256b/oyXAUuBP+vlurr82aQjQicAAAHqSURBVAGfTY/XSuDM3v5ZpstvAy7rsG2vHLNuPh8y/R3zFBNmZjmXl64hMzPrgoPAzCznHARmZjnnIDAzyzkHgZlZzjkIzHqRpFMk/azadZhVchCYmeWcg8CsE5I+JOl36dzz35RUlLRV0j+n88TfJ2lUuu0kSQ9q17z/rXPFv03SIkmPSFoq6a3pyw+SdJeSewXckV5NalY1DgKzDiQdD1wATIuISUAL8BckVzg3RMQ7gF8B16W7fA/4u4g4geTqztbldwA3RcRE4I9JrmKFZEbJK0nmmX8LMC3zb8qsG6VqF2DWB50GnAgsTv9Y708yyddOdk1E9n3gJ5KGAEMj4lfp8u8C/57O2zQ6Iu4GiIhtAOnr/S7SeWyU3AGrDvht9t+WWeccBGa7E/DdiLi63ULp8x2229f5WbZXPG7B/w6tytw1ZLa7+4CZkg6HtvvFHkPy72Vmus2FwG8jYhPwSsWNSj4M/CqSu0s1Svrz9DX6SRrQq9+FWQ/5LxGzDiJihaTPkdytrUAyO+VfA68BU9N1L5KMI0AyLfA30g/6NcBfpss/DHxT0g3pa5zXi9+GWY959lGzHpK0NSIGVbsOswPNXUNmZjnnFoGZWc65RWBmlnMOAjOznHMQmJnlnIPAzCznHARmZjn339xY2qDBXMPYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}